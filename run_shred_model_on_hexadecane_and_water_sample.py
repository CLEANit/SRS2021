# -*- coding: utf-8 -*-
"""Run SHRED model on hexadecane and water sample.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BjU2RWW2Jmy7kYPodloz7z470c-Tebh_

Importing libraries
"""

#Importing Libraries 
import torch 
import os
from os import path
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import imageio
from pathlib import Path
import torch.nn as nn
from sklearn.metrics import mean_squared_error

"""Dataset stored on google drive.
Mounting a virtual drive to getting access to the dataset.
"""

#Mounting a virtual drive on google drive
from google.colab import drive
drive.mount('/content/drive')

"""**Read_tiff** is a function that import the hyperspectral SRS images then convert it to a numpy array.

Function argument is path of the file follows by it's name.

"""

#Reading tiff images and store them in to a numpy array
def read_tiff(path) :
    """
    path - Path of the multipage-tiff file
    """
    img = Image.open(path)
    images = []
    for i in range (img.n_frames) : 
        img.seek(i)
        images.append(np.array(img))
    return np.array(images)

"""Input data are called **"target_data"** and **"noisy_data"**.

target_data is considered as the ground-truth which is used for comparision and recorded at a high input laser power.


noisy_data is considered as the dataset that recorded while the input laser power kept low. Decreasing the input laser power added some noise to the data.
"""

#Importing data, store it in to a numpy array (target_data) and then print the shape of it.  
target_data = read_tiff("/content/drive/My Drive/Data/2020-03-05 oil and water /Scan 2/60 mw/60 mW.tif") 
#printing size of the data file
print(target_data.shape)

#Importing data, store it in to a numpy array (noisy_data) and then print the shape of it.
noisy_data = read_tiff("/content/drive/My Drive/Data/2020-03-05 oil and water /Scan 2/20 mW/20 mW.tif") 
#printing size of the data file
print(noisy_data.shape)

"""Normalization and reshaping of the input data (ground-truth and noisy input)




"""

#Data Normalization [0-1].
mean_input_G = np.mean(target_data)
max_input_G = np.max(target_data)
min_input_G = np.min(target_data)

N_GT = np.zeros ((256,256,92))
for i in range (256):
  for j in range (256):
    for k in range (92):

      N_GT[i,j,k] = ((target_data[k,i,j]-mean_input_G))/(max_input_G-min_input_G)

#Check the normalization for GT
print(np.max(N_GT)-np.min(N_GT))

#Data Normalization [0-1].
mean_input_N = np.mean(noisy_data)
max_input_N = np.max(noisy_data)
min_input_N = np.min(noisy_data)
N_noisy = np.zeros ((256,256,92))
for i in range (256):
  for j in range (256):
    for k in range (92):

      N_noisy[i,j,k] = ((noisy_data[k,i,j]-mean_input_N))/(max_input_N-min_input_N)

#check the normalization for noisy input.
print(np.max(N_noisy)-np.min(N_noisy))

"""Removing hot pixels in the noisy dataset by averaging over neighbourhood pixels around the saturated pixel (hot pixel). """

#Averagin hot pixel neighbourhood
# for k in range(92):
P_N_Noisy = np.empty((256,256,92))
P_N_Noisy = N_noisy
avg_value_1 = np.empty((92))

for k in range (92):
  avg_value_1[k] = (1/3)*(np.mean(N_noisy[2:6,110:125,k])+np.mean(N_noisy[11:12,110:125])+np.mean(N_noisy[14:16,110:125,k]))

for i in range(13):
    for k in range(92):
      P_N_Noisy[7:11,118+i,k] = avg_value_1[k]+0.00005*np.random.uniform(0.8*avg_value_1[k],1.2*avg_value_1[k])
      P_N_Noisy[13,113+i,k] = avg_value_1[k]+0.00005*np.random.uniform(0.8*avg_value_1[k],1.2*avg_value_1[k])

"""Removing hot pixels in the noisy dataset by averaging over neighbourhood pixels around the saturated pixel (hot pixel). """

#Averagin hot pixel neighbourhood
# for k in range(92):
P_N_GT = np.empty((256,256,92))
P_N_GT = N_GT
avg_value_1 = np.empty((92))
avg_value_2 = np.empty((92))
avg_value_3 = np.empty((92))
avg_value_4 = np.empty((92))

for k in range (92):
  avg_value_1[k] = (1/3)*(np.mean(N_GT[0:6,111:126,k])+np.mean(N_GT[11:12,112:126,k])+np.mean(N_GT[14,112:126]))
  avg_value_3[k] = np.mean(N_GT[40,70:80,k])
  avg_value_4[k] = np.mean(N_GT[144,113:126,k])

for i in range(15):
    for k in range(92):
      P_N_GT[7:11,114+i,k] = avg_value_1[k]+0.00005*np.random.uniform(0.8*avg_value_1[k],1.2*avg_value_1[k])
      P_N_GT[12:14,113+i,k] = avg_value_1[k]+0.00005*np.random.uniform(0.8*avg_value_1[k],1.2*avg_value_1[k])
      P_N_GT[61,56+i,k] = P_N_GT[59,56+i,k]
      P_N_GT[41,70+i,k] = avg_value_3[k]+0.00005*np.random.uniform(0.8*avg_value_3[k],1.2*avg_value_3[k])
      P_N_GT[146,113+i,k] = avg_value_4[k]+0.00005*np.random.uniform(0.8*avg_value_4[k],1.2*avg_value_4[k])

"""Normalization for both ground-truth and noisy input.


Mean value = 0

STD = 1
"""

P_N_GT = (P_N_GT-np.mean(P_N_GT))/(np.max(P_N_GT)-np.min(P_N_GT))
P_N_Noisy = (P_N_Noisy-np.mean(P_N_Noisy))/(np.max(P_N_Noisy)-np.min(P_N_Noisy))

#Check point to see if normalization worked well.
print(np.max(P_N_GT)-np.min(P_N_GT))
print(np.max(P_N_Noisy)-np.min(P_N_Noisy))

"""Coverting the input **numpy array** to the **pytorch tensor**

Reshape it. 

"""

#Converting numpy array to pyorch tensor and copy it on GPU (CUDA).
target_input_t = P_N_GT.reshape((65536,-1))
target_input_t = torch.from_numpy(target_input_t).float()
target_input_t = target_input_t.view(-1,1,92)

#Converting numpy array to pyorch tensor and copy it on GPU (CUDA).
noisy_input_t = P_N_Noisy.reshape((65536,-1))
noisy_input_t = torch.from_numpy(noisy_input_t).float()
noisy_input_t = noisy_input_t.view(-1,1,92)

class Autoencoder(nn.Module):

  def __init__(self,zdims):
    super().__init__()
    self.zdims = zdims
    #Encoder layer
    self.encoder = nn.Sequential(nn.Conv1d(1,4,kernel_size = 4, stride = 2),
            nn.MaxPool1d(kernel_size = 4, stride = 2),
            nn.Tanh(),
                    
            
            nn.Conv1d(4,8,kernel_size=4, stride = 2),
            nn.MaxPool1d(kernel_size = 3,stride = 1),
            nn.Tanh(),
                     
            
            nn.Conv1d(8,12,kernel_size = 3, stride = 1),
            nn.MaxPool1d(kernel_size = 2,stride = 1),
            nn.Tanh(),

            nn.Conv1d(12,16,kernel_size = 2, stride = 1),
            nn.MaxPool1d(kernel_size = 2, stride = 1),
            nn.Tanh()
            
            )

    
    #Decoder layer
    self.decoder = nn.Sequential(nn.ConvTranspose1d(16,12,kernel_size = 2, stride = 2),
            nn.Tanh(),
            

            nn.ConvTranspose1d(12,8,kernel_size = 4,stride = 1),
            nn.Tanh(),
                        

            nn.ConvTranspose1d(8,4,kernel_size= 3,stride = 3),
            nn.Tanh(),

            nn.ConvTranspose1d(4,1,kernel_size = 12, stride = 4),
            nn.Tanh())
    

    #Deconv FC LAYER
    self.fc_e = nn.Linear(32,self.zdims)

    self.fc_d = nn.Linear(self.zdims,32)
        

  def encode(self,imgs):

      output = self.encoder(imgs)
      output = output.view(-1,32)
      output = self.fc_e(output)
      return output

  def decode(self,z):

      
      deconv_input = self.fc_d(z)
      deconv_input = deconv_input.view(-1,16,2)
      reconstructed_img = self.decoder(deconv_input)
      return reconstructed_img

  def forward(self,x):
    
      x = self.encode(x)
      reconstructed_img = self.decode(x)
      return reconstructed_img

#output of the NN
out_put = torch.zeros([65536,1,92],dtype=torch.float)

"""Loading the model parameters that trained before.

It will be loaded on a CPU.
"""

#loading the model parameters 
model = Autoencoder(zdims = 20)
model_save_name = 'Hexadecane and water 2021-02-17 (2)'
path = F"/content/drive/My Drive/{model_save_name}"
model.load_state_dict(torch.load(path,map_location = 'cpu'))

"""feeding input tensot to the model."""

#feeding model by the noisy input
out_put = model(noisy_input_t)

"""Mapping noisy input to the latent space, by feeding the noisy input to the encoder module."""

#mapping input data to the latent space
latent_space = model.encode(noisy_input_t)

"""Reshaping output of the NN and convert it to a numpy array."""

out_put = out_put.view(65536,92)
out_put = out_put.detach().cpu().numpy()
out_put = out_put.reshape(256,256,-1)
print(out_put.shape)

#Output of the NN values
max_out_put = np.max(out_put)
min_out_put = np.min(out_put)
mean_out_put = np.mean(out_put)

#Printing the out put min, max and mean
print ('mean = %f \n max = %f \n min = %f ' % (mean_out_put,max_out_put,min_out_put))
print(max_out_put-min_out_put)

"""r_out_put is normalized output of the NN in a way of having mean value of zero and standard deviation of 1."""

#defining reshaped out_put
r_out_put = np.empty((256,256,92))
r_out_put = (out_put-mean_out_put)/(max_out_put-min_out_put)
r_max_out_put = np.max(r_out_put)
r_min_out_put = np.min(r_out_put)
r_mean_out_put = np.mean(r_out_put)
print ('mean = %f \n max = %f \n min = %f ' % (r_mean_out_put,r_max_out_put,r_min_out_put))

"""Plot a slice of output to see how model works."""

plt.imshow(r_out_put[:,:,46], cmap = 'Spectral_r')
plt.colorbar()
plt.clim(-0.2,0.8)
plt.title('Reconstructed image')
plt.axis('off')

"""Ploting a spectral slice of grund-truth."""

plt.imshow(P_N_GT[:,:,46],cmap = 'Spectral_r')
plt.clim(-0.2,0.8)
plt.colorbar()
plt.title('Original data (High SNR)')
plt.axis('off')

"""Comparision between noisy input, output of the model and grund truth."""

#ploting a sample frame from input data
from mpl_toolkits.axes_grid1 import make_axes_locatable
fig,(ax1,ax2,ax3) = plt.subplots(1,3,figsize=(10, 10))

im1 = ax1.imshow(P_N_Noisy[:,:,46],cmap = 'Spectral_r')
divider = make_axes_locatable(ax1)
cax = divider.append_axes("right", size="5%", pad=0.05)
fig.colorbar(im1, cax=cax, orientation='vertical')

im2 = ax2.imshow(r_out_put[:,:,46], cmap = 'Spectral_r')
divider = make_axes_locatable(ax2)
cax = divider.append_axes("right", size="5%", pad=0.05)
fig.colorbar(im2, cax=cax, orientation='vertical')


im3 = ax3.imshow(P_N_GT[:,:,46], cmap = 'Spectral_r')
divider = make_axes_locatable(ax3)
cax = divider.append_axes("right", size="5%", pad=0.05)
fig.colorbar(im3, cax=cax, orientation='vertical')

ax1.set_title('Noisy Input', fontsize = 16)
ax2.set_title('Output of model', fontsize = 16)
ax3.set_title("Ground-Truth", fontsize = 16)
ax2.set_axis_off()
ax3.set_axis_off()
ax1.set_axis_off()

plt.show()

"""Defining x axis. which represents the Raman shift."""

# x represents Raman shift.
x = np.linspace(2640.95,3063.05,92)
x.shape

"""Ploting Raman spectrum of an pixel for recovered hyperspectral image.

Output of NN.
"""

#Ploting Raman spectrum of a pixel in recovered hyperspectral image.
plt.plot(x,r_out_put[150,150,:]*(1/np.max(r_out_put[150,150,:])), color = 'r', label = 'Reconstructed Signal', linewidth = 2)
plt.ylabel('Normalized Intensity (a.u.)', fontsize = 14.5)
plt.xlabel('Raman Shift $\mathregular{cm^-1}$', fontsize = 14.5)
plt.ylim(-0.4,1.1)
y_ticks = np.arange(-0.2, 1.1, 0.4)
plt.yticks(y_ticks,fontsize = 12.5)
plt.xticks(fontsize = 12.5)
plt.legend(prop={'size': 14.5})
plt.xticks(fontsize=14.5)
plt.tick_params(width = 3.5,length = 5,direction = "in")

#Ploting Raman spectrum of a pixel in GT hyperspectral image.
plt.plot(x,P_N_GT[150,150,:]*(1/np.max(P_N_GT[150,150,:])), color = 'g', label = 'Ground-Truth', linewidth = 2)
plt.ylabel('Normalized Intensity (a.u.)', fontsize = 14.5)
plt.xlabel('Raman Shift $\mathregular{cm^-1}$', fontsize = 14.5)
plt.ylim(-0.4,1.1)
y_ticks = np.arange(-0.2, 1.1, 0.4)
plt.yticks(y_ticks,fontsize = 12.5)
plt.xticks(fontsize = 12.5)
plt.legend(prop={'size': 14.5})
plt.xticks(fontsize=14.5)
plt.tick_params(width = 3.5,length = 5,direction = "in")

#Ploting Raman spectrum of a pixel in noisy_input hyperspectral image.
plt.plot(x,P_N_Noisy[150,150,:]*(1/np.max(P_N_Noisy[150,150,:])), color = 'B', label = 'Noisy Input', linewidth = 2)
plt.ylabel('Normalized Intensity (a.u.)', fontsize = 14.5)
plt.xlabel('Raman Shift $\mathregular{cm^-1}$', fontsize = 14.5)
plt.ylim(-0.4,1.1)
y_ticks = np.arange(-0.2, 1.1, 0.4)
plt.yticks(y_ticks,fontsize = 12.5)
plt.xticks(fontsize = 12.5)
plt.legend(prop={'size': 14.5})
plt.xticks(fontsize=14.5)
plt.tick_params(width = 3.5,length = 5,direction = "in")

"""Quantification the performance of the model by substracting the recovered signal (NN) from ground-truth. 

Calculating 'Mean Squared Error (MSE)' of that substraction.

"""

#Ploting residual signal to determine how much NN signal is noisy in comparision to ground truth signal

plt.plot(x,(P_N_Noisy[60,40,:]*(1/np.max(P_N_Noisy  [60,40,:])))-(P_N_GT[60,40,:]*(1/np.max(P_N_GT[60,40,:]))),color='orange', label = '(Noisy Signal-Ground Truth)', linewidth = 2)
MSE_2 = mean_squared_error((P_N_Noisy[60,40,:]*(1/np.max(P_N_Noisy[60,40,:]))),(P_N_GT[60,40,:]*(1/np.max(P_N_GT[60,40,:]))))

def constant_function_2(x):
    return MSE_2

plt.ylabel('Residual', fontsize = 14.5)
plt.xlabel('Raman Shift $cm^-1$', fontsize = 14.5)
plt.legend(prop={'size': 12.5})
plt.tick_params(width = 2.5,length = 4,direction = "in")
plt.xticks(fontsize=14.5)
y_ticks = np.arange(-0.6, 0.8, 0.2)
plt.yticks(y_ticks,fontsize = 14.5)

#Ploting residual signal to determine how much NN signal is noisy in comparision to ground truth signal

plt.plot(x,(r_out_put[60,40,:]*(1/np.max(r_out_put[60,40,:])))-(P_N_GT[60,40,:]*(1/np.max(P_N_GT[60,40,:]))),color='orange', label = '(Output_NN-Ground Truth)', linewidth = 2)
plt.ylabel('Residual', fontsize = 14.5)
MSE_1 = mean_squared_error((r_out_put[60,40,:]*(1/np.max(r_out_put[60,40,:]))),(P_N_GT[60,40,:]*(1/np.max(P_N_GT[60,40,:]))))

def constant_function_1(x):
    return MSE_1

plt.xlabel('Raman Shift $\mathregular{cm^-1}$', fontsize = 14.5)
plt.legend(prop={'size': 12.5})
plt.xticks(fontsize = 14.5)
plt.tick_params(width = 2.5,length = 4,direction = "in")
plt.xticks(fontsize = 14.5)
y_ticks = np.arange(-0.6, 0.8, 0.2)
plt.yticks(y_ticks,fontsize = 14.5)

#print numerical value of MSE_1
print(MSE_1)

#printing numerical value of MSE_2
MSE_2

#printing shape of latent space.
latent_space.shape

#Converting pytorch tensor to numpy array, then copy it on cup.
latent_space = latent_space.detach().cpu().numpy()

"""Finding the best number of clusters by applying elbow method.

Then k-mean clustering and PCA algorythm will be used in order to image segmentation (material classification)
"""

#Elbow method for finding the best number of clusters.
from sklearn.cluster import KMeans
import pandas as pd
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
wcss = []

for i in range (1,20):
  kmeans = KMeans(n_clusters = i)
  kmeans.fit(latent_space)
  wcss.append(kmeans.inertia_)
plt.plot(range(1,20),wcss)
plt.xticks(np.arange(1, 20, 2.0))
plt.title('Finding the best number of clusers')
plt.xlabel("Number of Clusters", fontsize = 14)
plt.ylabel("Error", fontsize = 14)
plt.xticks(fontsize=13.5)
plt.yticks(fontsize=13.5)
plt.tick_params(width = 3,length = 3,direction = "in")
plt.show()

"""Here, k-mean clustering and PCA are going to apply in order to do image segmentation."""

#Initialize our scaler
scaler = StandardScaler()

#Applying normalization to latent space data. Also make it as a Panda array.
latent_space = pd.DataFrame(scaler.fit_transform(latent_space))

#Applying K_Mean method by assumption of having 8 clussters in out dataset. (latent space)
Kmeans = KMeans(n_clusters = 2)
Kmeans.fit(latent_space)
clusters = Kmeans.predict(latent_space)

#This counts number of data in every clusters. And store them in a group_# list. 
group_1 = []
group_2 = []

for i in range(65536) :
  if clusters[i] == 0:
    group_1.append (clusters[i])
  elif clusters[i] == 1:
    group_2.append(clusters[i])

#Printing the number of data assigned in each cluster.
print(len(group_1),len(group_2))

#Adding the clusters colume to the latent_space panda.
latent_space["Clusters"] = clusters

#plotting 5 first data of the new latent_space
latent_space.head()

"""Apply PCA method on latent space."""

#PCA with two principal components
pca_2d = PCA(n_components=2)

#PCA with three principal components
pca_3d = PCA(n_components=3)

#This DataFrame contains the two principal components that will be used
#for the 2-D visualization mentioned above
PCs_2d = pd.DataFrame(pca_2d.fit_transform(latent_space.drop(["Clusters"], axis=1)))

#And this DataFrame contains three principal components that will aid us
#in visualizing our clusters in 3-D
PCs_3d = pd.DataFrame(pca_3d.fit_transform(latent_space.drop(["Clusters"], axis=1)))

#"PC1_2d" means: 'The first principal component of the components created for 2-D visualization, by PCA.'
#And "PC2_2d" means: 'The second principal component of the components created for 2-D visualization, by PCA.'
PCs_2d.columns = ["PC1_2d", "PC2_2d"]
PCs_3d.columns = ["PC1_3d", "PC2_3d", "PC3_3d"]

#Adding columns of PCs_2d,PCs_3d to the latent_space_f panda array. 
latent_space = pd.concat([latent_space,PCs_2d,PCs_3d], axis=1, join='inner')

#plotting 5 first data of the latent_space_f
latent_space.head()

#Note that all of the DataFrames below are sub-DataFrames of 'new_latent'.
#This is because we intend to plot the values contained within each of these DataFrames.
cluster0 = latent_space[latent_space["Clusters"] == 0]
cluster1 = latent_space[latent_space["Clusters"] == 1]

#Instructions for building the 2-D plot
import plotly as py
import plotly.graph_objs as go
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot

#trace0 is for 'Cluster 0'
trace0 = go.Scatter(
                    x = cluster0["PC1_2d"],
                    y = cluster0["PC2_2d"],
                    mode = "markers",
                    name = "Cluster 0",
                    #marker = dict(color = 'rgba(255, 128, 255, 0.8)'),
                    text = None)

#trace1 is for 'Cluster 1'
trace1 = go.Scatter(
                    x = cluster1["PC1_2d"],
                    y = cluster1["PC2_2d"],
                    mode = "markers",
                    name = "Cluster 1",
                    #marker = dict(color = 'rgba(255, 128, 2, 0.8)'),
                    text = None)


data = [trace0,trace1]

title = "Visualizing Clusters in Two Dimensions Using PCA"

layout=go.Layout(title = title, xaxis = dict(title = 'PC1'), yaxis = dict(title = 'PC2'))
          
fig=go.Figure(data=data, layout=layout)

fig.show()

#Instructions for building the 3-D plot

#trace0 is for 'Cluster 0'
trace0 = go.Scatter3d(
                    x = cluster0["PC1_3d"],
                    y = cluster0["PC2_3d"],
                    z = cluster0["PC3_3d"],
                    mode = "markers",
                    name = "Cluster 0",
                    marker = dict(color = 'rgba(255, 128, 255, 0.8)'),
                    text = None)

#trace1 is for 'Cluster 1'
trace1 = go.Scatter3d(
                    x = cluster1["PC1_3d"],
                    y = cluster1["PC2_3d"],
                    z = cluster1["PC3_3d"],
                    mode = "markers",
                    name = "Cluster 1",
                    #marker = dict(color = 'rgba(255, 128, 2, 0.8)'),
                    text = None)

data = [trace0,trace1]

title = "Visualizing Clusters in Three Dimensions Using PCA"

layout=go.Layout(title = title, xaxis = dict(title = 'PC1'), yaxis = dict(title = 'PC2'))
          
fig=go.Figure(data=data, layout=layout)

fig.show()

#Now it is the time to color code every single pixel and plot the whole image to see if clustering works well. 
#Panda converted to Numpy array, every single pixel is color coded by k_mean algorythm.
Latet_cluster_img = latent_space["Clusters"].to_numpy()
Latet_cluster_img = np.reshape(Latet_cluster_img,(256,256))
print("Shape of the color coded image is:", Latet_cluster_img.shape)

#Ploting the image
from matplotlib.colors import ListedColormap
cmap = ListedColormap(['red','blue'])
plt.imshow(Latet_cluster_img, cmap = cmap)
plt.axis("off")