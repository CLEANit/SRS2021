# -*- coding: utf-8 -*-
"""Running UHRED model for the mineral sample 2021-02-19.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bv8xJzR8RMpL5LclpSFT24u4Uxf8a24u

Importing Libraris
"""

#Importing Libraries 
import torch 
import os
from os import path
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import imageio
from pathlib import Path
import plotly.express as px
import torch.nn as nn
from scipy import ndimage 
from sklearn.cluster import KMeans
import pandas as pd
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import plotly as py
import plotly.graph_objs as go
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot

"""Mounting a virtual drive on google drive.

"""

#Mounting a virtual drive
from google.colab import drive
drive.mount('/content/drive')

"""**Read_tiff** is a function that import the hyperspectral SRS images then convert it to a numpy array.

Function argument is path of the file follows by it's name.

"""

#Reading tiff image and store it in a numpy array
def read_tiff(path) :
    """
    path - Path of the multipage-tiff file
    """
    img = Image.open(path)
    images = []
    for i in range (img.n_frames) : 
        img.seek(i)
        images.append(np.array(img))
    return np.array(images)

"""Calling the **read_tiff** function to read the input dataset from google drive."""

#Importing data from goolge drive.
data = read_tiff("/content/drive/MyDrive/Data/Li project-Raw data 4 fields of view/Scan 1 in Phase comp.tif")
#printing size of the data file
print ("Input data has the shape: \n",data.shape)

"""Finding max,min and mean value of the input dataset."""

#Reading min, max and mean value of the imported data
mean_input = np.mean(data)
max_input = np.max(data)
min_input = np.min(data)
differenc = max_input-min_input
print("Input data statistical features:\n")
print("//////////////////////////////////////\n")
print('\tMean value is = %f \n \tMax value is = %f \n \t Min value is = %f \n \tDifference of max and min value is = %f ' % (mean_input,max_input,min_input, differenc))

"""Reshaping the input dataset."""

#Reshaping data input
input = np.empty((256,256,909))
for i in range(256):
  for j in range (256):
    for k in range (909):
      input [i,j,k] = data[k,i,j]

"""Normalizing input data (mean value of 0, standard deviation of 1)"""

#Input normalization
input = (input-np.mean(input))/(np.max(input)-np.min(input))

#Check to see if normalization worked well.
print(np.max(input)-np.min(input))

"""Ploting a slice of hyperspectral SRS image."""

plt.imshow(input[:,:,141], cmap = 'Spectral_r')
plt.axis('off')
plt.colorbar()

"""Coverting the input **numpy array** to the **pytorch tensor**.

Reshape it. 
"""

#Converting input numpy array to torch Tensor.
input_t = input.reshape((65536,-1))
input_t = torch.from_numpy(input_t).float()
input_t = input_t.view(-1,1,909)

#printing shape on input Torch Tensor.
print(input_t.shape)

"""## **Autoencoder model**"""

class Autoencoder(nn.Module):

  def __init__(self,zdims):
    super().__init__()
    self.zdims = zdims
    #Encoder layer
    self.encoder = nn.Sequential(nn.Conv1d(1,4,kernel_size = 4, stride = 3),
            nn.MaxPool1d(kernel_size = 4, stride = 3),
            nn.Tanh(),
                    
            
            nn.Conv1d(4,8,kernel_size=4, stride = 2),
            nn.MaxPool1d(kernel_size = 4,stride = 2),
            nn.Tanh(),
                     
            
            nn.Conv1d(8,12,kernel_size = 4, stride = 2),
            nn.MaxPool1d(kernel_size = 4,stride = 1),
            nn.Tanh(),

            nn.Conv1d(12,16,kernel_size = 4, stride = 1),
            nn.MaxPool1d(kernel_size = 3,stride = 1),
            nn.Tanh()
            
            )

    
    #Decoder layer
    self.decoder = nn.Sequential(nn.ConvTranspose1d(16,12,kernel_size = 5, stride = 2),
            nn.Tanh(),
            

            nn.ConvTranspose1d(12,8,kernel_size = 5,stride = 3),
            nn.Tanh(),
                        

            nn.ConvTranspose1d(8,4,kernel_size= 12,stride = 4),
            nn.Tanh(),

            nn.ConvTranspose1d(4,1,kernel_size = 18, stride = 9),
            nn.Tanh())
    

    #Deconv FC LAYER
    self.fc_e = nn.Linear(32,self.zdims)
    self.fc_d = nn.Linear(self.zdims,32)
    

  def encode(self,imgs):

      output = self.encoder(imgs)
      output = output.view(-1,32)
      output = self.fc_e(output)
      return output

  def decode(self,z):

      deconv_input = self.fc_d(z)
      deconv_input = deconv_input.view(-1,16,2)
      reconstructed_img = self.decoder(deconv_input)
      return reconstructed_img

  def forward(self,x):
    
      x = self.encode(x)
      reconstructed_img = self.decode(x)
      return reconstructed_img

#Output of the NN
out_put = torch.zeros([65536,1,909],dtype=torch.float)

"""Loading the model parameters that trained before.

It will be loaded on A CPU.

  
"""

#loading the model parameters 
model = Autoencoder(zdims=20)
model_save_name = 'Li 2021-02-19'
path = F"/content/drive/My Drive/{model_save_name}"
model.load_state_dict(torch.load(path,map_location = 'cpu'))

"""Feeding the input data to our pre-trained model and storing its output in a Torch tensor...

"""

#Feeding input to the trained NN.
out_put = model(input_t)

"""For classifiction the technic that we are going to use is taking advantage of **Latent space**. This requires to feed in all input data to just Encoder layer and then by applying one of clustering method like k_mean labeling every single pixel. 

"""

#projecting input data to latent space for the purpos of classification. 
latent_space = model.encode(input_t)

#checking latent space shape.
latent_space.shape

"""Reshaping output of the model. """

#Reshaping output Torch tensor, and make it plotable.
out_put = out_put.view(65536,909)
out_put = out_put.detach().cpu().numpy()
out_put = out_put.reshape(256,256,-1)
out_put.shape

#Output of the NN values
max_out_put = np.max(out_put)
min_out_put = np.min(out_put)
mean_out_put = np.mean(out_put)
#Printing the out put min, max and mean
print("Output data statistical features:\n")
print("//////////////////////////////////////\n")
print ('\tmean = %f \n \tmax = %f \n \tmin = %f ' % (mean_out_put,max_out_put,min_out_put))
print('\tVariance of the Output data:',max_out_put-min_out_put)

#Plointing a single frame of the ground truth image.
plt.imshow(input[:,:,141], cmap = "Spectral_r")
plt.colorbar()
plt.axis("off")
plt.clim(-0.4,0.4)
# plt.title('Original data (High SNR)')

#Ploting a single frame of the Reconstructed hyperimage (Normalized output of the model).
plt.imshow(out_put[:,:,141],cmap = "Spectral_r")
plt.clim(-0.4,0.4)
# plt.title('Reconstructed Image')
plt.axis("off")
plt.colorbar()

"""Comparision between input and output of the model."""

#ploting a sample frame from input data
from mpl_toolkits.axes_grid1 import make_axes_locatable
fig,(ax1,ax2) = plt.subplots(1,2,figsize=(10, 10))

im1 = ax1.imshow(input[:,:,141],cmap = 'Spectral_r')
divider = make_axes_locatable(ax1)
cax = divider.append_axes("right", size="5%", pad=0.05)
fig.colorbar(im1, cax=cax, orientation='vertical')

im2 = ax2.imshow(out_put[:,:,141], cmap = 'Spectral_r')
divider = make_axes_locatable(ax2)
cax = divider.append_axes("right", size="5%", pad=0.05)
fig.colorbar(im2, cax=cax, orientation='vertical')


ax1.set_title('Input', fontsize = 16)
ax2.set_title('Output of model', fontsize = 16)
ax2.set_axis_off()
ax1.set_axis_off()


plt.show()

#Better plotting way to s257ee more details with corresponde pixel
px.imshow(out_put[:,:,141])

"""Checking specrtral reconstruction. 
Every single pixel contains full spectrum information like a 1D signal. 

"""

# Ploting a single pixel spectrum of the reconstructed data.
plt.plot(out_put[108,20,:],color = 'r', label = 'Pixel (108,20)')
plt.xlabel('Hyperspectral Index')
plt.tick_params(width = 2,length = 4,direction = "in")
plt.legend(prop={'size': 16.5},shadow=True, bbox_to_anchor=(0.6, 0.22))
plt.xticks(fontsize=16.5)
y_ticks = np.arange(-0.2, 0.6, 0.1)
plt.yticks(y_ticks,fontsize = 16.5)
plt.ylabel('Normalized Intensity',fontsize = 16.5)
plt.xlabel('Hyperspectral index', fontsize = 16.5)

# Ploting a single pixel spectrum of the reconstruction hyperstack and ground truth one on top of each other
plt.plot(input[108,20,:],color = 'b', label = 'Pixel (108,20)')
plt.tick_params(width = 2,length = 4,direction = "in")
plt.legend(prop={'size': 16.5},shadow=True, bbox_to_anchor=(0.6, 0.22))
plt.xticks(fontsize=16.5)
y_ticks = np.arange(-0.2, 0.6, 0.1)
plt.yticks(y_ticks,fontsize = 16.5)
plt.ylabel('Normalized Intensity',fontsize = 16.5)
plt.xlabel('Hyperspectral index', fontsize = 16.5)

#Ploting input and output of the model on top of each other.

plt.plot(out_put[44,180,:], color = 'r',label = 'Pixel (44,180)')
plt.plot(input[44,180,:], color = 'b', label = 'Pixel (44,180')
plt.ylabel('Normalized Intensity', fontsize = 14.5)
plt.xlabel('Hyperspectral index', fontsize = 14.5)
plt.legend(prop={'size': 14.5},shadow=True, bbox_to_anchor=(0.5, 0.7))
plt.tick_params(width = 2,length = 4,direction = "in")
plt.xticks(fontsize=13.5)
y_ticks = np.arange(-0.2, 0.6, 0.1)
plt.yticks(y_ticks,fontsize = 14.5)
plt.ylabel('Normalized Intensity')

#Converting latent_sapce tensor to an numpy array. make it ready for printing stuff.
latent_space = latent_space.detach().cpu().numpy()

"""Applying **Elbow method** to see how many clusters are required. It is based on calculating error of k_mean versus number of clusters. """

#Elbow method for finding the best number of clusters.
wcss = []

for i in range (1,20):
  kmeans = KMeans(n_clusters = i)
  kmeans.fit(latent_space)
  wcss.append(kmeans.inertia_)
plt.plot(range(1,20),wcss)
plt.xticks(np.arange(1, 20, 2.0))
plt.title('Finding the best number of clusers')
plt.xlabel("Number of Clusters", fontsize = 14)
plt.ylabel("Error", fontsize = 14)
plt.xticks(fontsize=13.5)
plt.yticks(fontsize=13.5)
plt.tick_params(width = 3,length = 3,direction = "in")
plt.show()

"""Here, k-mean clustering and PCA are going to apply in order to do image segmentation and classification."""

#Initialize our scaler
scaler = StandardScaler()

#Applying normalization to latent space data. Also make it as a Panda array.
latent_space = pd.DataFrame(scaler.fit_transform(latent_space))

#Plotting 5 first data on latent space data.
latent_space.head()

#Applying K_Mean method by assumption of having 8 clussters in out dataset. (latent space)
Kmeans = KMeans(n_clusters = 5)
Kmeans.fit(latent_space)
clusters = Kmeans.predict(latent_space)

#This counts number of data in every clusters. And store them in a group_# list. 
group_1 = []
group_2 = []
group_3 = []
group_4 = []
group_5 = []


for i in range(65536) :
  if clusters[i] == 0:
    group_1.append (clusters[i])
  elif clusters[i] == 1:
    group_2.append(clusters[i])
  elif clusters[i] == 2:
    group_3.append(clusters[i])
  elif clusters[i] == 3:
    group_4.append(clusters[i])
  elif clusters[i] == 4:
    group_5.append(clusters[i])

#Printing the number of data assigned in each cluster.
print(len(group_1),len(group_2),len(group_3),len(group_4),len(group_5))

#Adding the clusters colume to the latent_space_f panda.
latent_space["Clusters"] = clusters

#plotting 5 first data of the new latent_space_f
latent_space.head()

"""Because latent_space is a 20 dimenssion vector, this is why it is requred to apply dimenssion reduction techniques due to represent the clustering result."""

#PCA with two principal components
pca_2d = PCA(n_components=2)

#PCA with three principal components
pca_3d = PCA(n_components=3)

#This DataFrame contains the two principal components that will be used
#for the 2-D visualization mentioned above
PCs_2d = pd.DataFrame(pca_2d.fit_transform(latent_space.drop(["Clusters"], axis=1)))

#And this DataFrame contains three principal components that will aid us
#in visualizing our clusters in 3-D
PCs_3d = pd.DataFrame(pca_3d.fit_transform(latent_space.drop(["Clusters"], axis=1)))

#"PC1_2d" means: 'The first principal component of the components created for 2-D visualization, by PCA.'
#And "PC2_2d" means: 'The second principal component of the components created for 2-D visualization, by PCA.'
PCs_2d.columns = ["PC1_2d", "PC2_2d"]
PCs_3d.columns = ["PC1_3d", "PC2_3d", "PC3_3d"]

#Adding columns of PCs_2d,PCs_3d to the latent_space_f panda array. 
latent_space = pd.concat([latent_space,PCs_2d,PCs_3d], axis=1, join='inner')

#plotting 5 first data of the latent_space_f
latent_space.head()

#Note that all of the DataFrames below are sub-DataFrames of 'new_latent'.
#This is because we intend to plot the values contained within each of these DataFrames.
cluster0 = latent_space[latent_space["Clusters"] == 0]
cluster1 = latent_space[latent_space["Clusters"] == 1]
cluster2 = latent_space[latent_space["Clusters"] == 2]
cluster3 = latent_space[latent_space["Clusters"] == 3]
cluster4 = latent_space[latent_space["Clusters"] == 4]

#Instructions for building the 2-D plot

#trace0 is for 'Cluster 0'
trace0 = go.Scatter(
                    x = cluster0["PC1_2d"],
                    y = cluster0["PC2_2d"],
                    mode = "markers",
                    name = "Cluster 0",
                    #marker = dict(color = 'rgba(255, 128, 255, 0.8)'),
                    text = None)

#trace1 is for 'Cluster 1'
trace1 = go.Scatter(
                    x = cluster1["PC1_2d"],
                    y = cluster1["PC2_2d"],
                    mode = "markers",
                    name = "Cluster 1",
                    #marker = dict(color = 'rgba(255, 128, 2, 0.8)'),
                    text = None)

#trace2 is for 'Cluster 2'
trace2 = go.Scatter(
                    x = cluster2["PC1_2d"],
                    y = cluster2["PC2_2d"],
                    mode = "markers",
                    name = "Cluster 2",
                    #marker = dict(color = 'rgba(0, 255, 200, 0.8)'),
                    text = None)

#trace3 is for 'Cluster 3'
trace3 = go.Scatter(
                    x = cluster3["PC1_2d"],
                    y = cluster3["PC2_2d"],
                    mode = "markers",
                    name = "Cluster 3",
                    #marker = dict(color = 'rgba(3, 255, 200, 0.5)'),
                    text = None)

#trace4 is for 'Cluster 4'
trace4 = go.Scatter(
                    x = cluster4["PC1_2d"],
                    y = cluster4["PC2_2d"],
                    mode = "markers",
                    name = "Cluster 4",
                    #marker = dict(color = 'rgba(0, 255, 200, 0.6)'),
                    text = None)

data = [trace0,trace1,trace2,trace3,trace4]

title = "Visualizing Clusters in Two Dimensions Using PCA"

layout=go.Layout(title = title, xaxis = dict(title = 'PC1'), yaxis = dict(title = 'PC2'))
          
fig=go.Figure(data=data, layout=layout)

fig.show()

#Instructions for building the 3-D plot

#trace0 is for 'Cluster 0'
trace0 = go.Scatter3d(
                    x = cluster0["PC1_3d"],
                    y = cluster0["PC2_3d"],
                    z = cluster0["PC3_3d"],
                    mode = "markers",
                    name = "Cluster 0",
                    marker = dict(color = 'rgba(255, 128, 255, 0.8)'),
                    text = None)

#trace1 is for 'Cluster 1'
trace1 = go.Scatter3d(
                    x = cluster1["PC1_3d"],
                    y = cluster1["PC2_3d"],
                    z = cluster1["PC3_3d"],
                    mode = "markers",
                    name = "Cluster 1",
                    #marker = dict(color = 'rgba(255, 128, 2, 0.8)'),
                    text = None)

#trace2 is for 'Cluster 2'
trace2 = go.Scatter3d(
                    x = cluster2["PC1_3d"],
                    y = cluster2["PC2_3d"],
                    z = cluster2["PC3_3d"],
                    mode = "markers",
                    name = "Cluster 2",
                    #marker = dict(color = 'rgba(0, 255, 200, 0.8)'),
                    text = None)

#trace3 is for 'Cluster 3'
trace3 = go.Scatter3d(
                    x = cluster3["PC1_3d"],
                    y = cluster3["PC2_3d"],
                    z = cluster3["PC3_3d"],
                    mode = "markers",
                    name = "Cluster 3",
                    #marker = dict(color = 'rgba(3, 255, 200, 0.5)'),
                    text = None)

#trace4 is for 'Cluster 4'
trace4 = go.Scatter3d(
                    x = cluster4["PC1_3d"],
                    y = cluster4["PC2_3d"],
                    z = cluster4["PC3_3d"],
                    mode = "markers",
                    name = "Cluster 4",
                    #marker = dict(color = 'rgba(0, 255, 200, 0.6)'),
                    text = None)


data = [trace0,trace1, trace4,trace3,trace4]

title = "Visualizing Clusters in Three Dimensions Using PCA"

layout=go.Layout(title = title, xaxis = dict(title = 'PC1'), yaxis = dict(title = 'PC2'))
          
fig=go.Figure(data=data, layout=layout)

fig.show()

#Now it is the time to color code every single pixel and plot the whole image to see if clustering works well. 
#Panda converted to Numpy array, every single pixel is color coded by k_mean algorythm.
Latet_cluster_img = latent_space["Clusters"].to_numpy()
Latet_cluster_img = np.reshape(Latet_cluster_img,(256,256))
print("Shape of the color coded image is:", Latet_cluster_img.shape)

#Ploting the image
from matplotlib.colors import ListedColormap
cmap = ListedColormap(["red", "gray","green","blue","orange"])
plt.imshow(Latet_cluster_img, cmap = cmap)
plt.axis("off")

#Ploting the image
plt.imshow(Latet_cluster_img, cmap = "CMRmap")
plt.axis("off")